{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955c2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1671172972475 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a29d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# THIS NEEDS TO BE CHANGED BASED ON DEVICE\n",
    "fin_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/finance_data_II.csv')\n",
    "# display(fin_df.head(3))\n",
    "TOTAL_ROWS = len(fin_df.index) - 1\n",
    "TRAIN_SIZE = math.ceil(TOTAL_ROWS * .75)\n",
    "\n",
    "# Scale everything from 0 to 1\n",
    "date = fin_df.pop('Date')           # Store the date column\n",
    "col_names = list(fin_df.columns)    # Store the column names lost in conversion to numpy array\n",
    "\n",
    "x = fin_df.values #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "fin_df = pd.DataFrame(x_scaled, columns=col_names)\n",
    "fin_df = pd.concat((date, fin_df), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Twitter data\n",
    "STOCK = 'SPX'\n",
    "twt_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/twt_data/SPX.csv')\n",
    "# Round to the date\n",
    "# round_time_pattern = \" \" + \".*\"\n",
    "# twt_df['Date'] = pd.to_datetime(twt_df['Date'])\n",
    "# twt_df['Date'] = twt_df['Date'].dt.round('D')\n",
    "# twt_df['Date'] = twt_df['Date'].astype(str)\n",
    "count = 0\n",
    "# for date in twt_df['Date']:\n",
    "#     date = re.sub(round_time_pattern, '', date)\n",
    "#     date = re.sub(r\"\\-\",'/', date)\n",
    "#     twt_df.loc[count, 'Date'] = date\n",
    "#     count = count + 1\n",
    "\n",
    "display(twt_df)\n",
    "# display(fin_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "combine the stock data and the twitter sentiment data using this function\n",
    "Order: stock, twitter data, finance data\n",
    "'''\n",
    "def combine_data(STOCK, t_df, f_df):\n",
    "    combined_df = pd.DataFrame()\n",
    "    fin_name = \"fin_\" + STOCK\n",
    "    twt_name = \"twt_\" + STOCK\n",
    "    \n",
    "    \n",
    "    # Select date and stock for fin data\n",
    "    f_df = f_df[['Date', STOCK]]\n",
    "    f_df.rename(columns={STOCK: fin_name}, inplace=True)\n",
    "    # display(f_df.head(2))\n",
    "    # display(t_df.head(2))\n",
    "    \n",
    "    # Remove all dates from fin_df that don't occur in twt_df\n",
    "    count = 0\n",
    "    fin_dates = f_df.iloc[:,0]\n",
    "    for date in fin_dates:\n",
    "        # print(date)\n",
    "        # print(twt_df['Date'].values)\n",
    "        if date not in t_df['Date'].values:\n",
    "            f_df.drop(fin_df[fin_df['Date'] == date].index, inplace = True)\n",
    "            # print(\"no match\")\n",
    "           \n",
    "            # fin_df.drop([date])\n",
    "\n",
    "    # Rename the column for twt data\n",
    "    t_df.rename(columns={\"$\" + STOCK: twt_name}, inplace=True)    \n",
    "\n",
    "    # Remove move all dates in twt_df that don't occur in fin_df\n",
    "    twt_dates = t_df.iloc[:,0]\n",
    "    for date in twt_dates:\n",
    "        if date  not in f_df['Date'].values:\n",
    "            t_df.drop(t_df[t_df['Date'] == date].index, inplace = True)\n",
    "              # print(\"no match\")\n",
    "\n",
    "    display(t_df)\n",
    "    display(f_df)\n",
    "\n",
    "    # THERE SHOULD BE A LINE FOR CONCATENTATING THE t_df and f_df int combined_df. IDK WHERE IT WENT\n",
    "    # Here's how: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to combine the twitter data and the stock data\n",
    "combined_data_df = combine_data(STOCK, twt_df, fin_df)\n",
    "display(combine_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93835ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/finance_data.csv').convert_dtypes()\n",
    "# TOTAL_ROWS = len(df.index) - 1\n",
    "# TRAIN_SIZE = math.ceil(TOTAL_ROWS * .75)\n",
    "\n",
    "# counter = 0\n",
    "# for label, col in df.iteritems():\n",
    "#     if label != 'Date':\n",
    "#         df.loc[:, label] = col.str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# # Scale everything from 0 to 1\n",
    "# # Store the date column\n",
    "# dates = df['Date']\n",
    "# df = df.drop('Date', axis=1)\n",
    "# df = (df-df.min())/(df.max()-df.min())\n",
    "# df = pd.concat((dates, df), 1)\n",
    "\n",
    "# display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e38a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all training data to a DataFrame\n",
    "df_train = pd.DataFrame()\n",
    "df_train = df.iloc[0:TRAIN_SIZE]\n",
    "\n",
    "# Add all the testing data to a DataFrame\n",
    "df_test = pd.DataFrame()\n",
    "df_test = df.iloc[TRAIN_SIZE:] \n",
    "display(df_train.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c23999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left over from the regression\n",
    "y_train = df_train['AMZN']\n",
    "x_train = df_train.loc[:,'SPX':'JNJ']\n",
    "\n",
    "x_train_lm = sm.add_constant(x_train)\n",
    "lr_1 = sm.OLS(y_train, x_train_lm)\n",
    "lr_1 = sm.OLS(y_train, x_train_lm).fit()\n",
    "lr_1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import re                                           # regular expressions\n",
    "import nltk\n",
    "import nltk.corpus as corpus                        # nltk package for reading files\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as stopwords      # words such as 'the','be','an', that don't significantly impact the sentiment\n",
    "from nltk.stem import WordNetLemmatizer             # Groups words\n",
    "from nltk.tokenize import word_tokenize             # Splits text into tokens\n",
    "import collections\n",
    "\n",
    "# Will be used later on\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# import sklearn\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>2020-04-09 00:00:03+00:00</td>\n",
       "      <td>$HEXO target price is $2.21, HEXO has a upside...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13047</th>\n",
       "      <td>2020-04-09 02:23:18+00:00</td>\n",
       "      <td>#germany issuing €130.5b in 7 &amp;amp; 15-yr #bon...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>2020-04-09 03:59:33+00:00</td>\n",
       "      <td>Wells Fargo &amp;amp; Co Reiterates “Buy” Rating f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>2020-04-09 05:58:02+00:00</td>\n",
       "      <td>This is not a favorable time to trade big. Why...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>2020-04-09 14:42:56+00:00</td>\n",
       "      <td>RT @amir: New: Microsoft’s rival to AWS, calle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929773</th>\n",
       "      <td>2020-07-16 16:11:19+00:00</td>\n",
       "      <td>Picked $amzn 3300 for earnings around 22. Shou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929272</th>\n",
       "      <td>2020-07-16 16:44:54+00:00</td>\n",
       "      <td>$AMZN $2992 you’re welcome</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928299</th>\n",
       "      <td>2020-07-16 17:50:52+00:00</td>\n",
       "      <td>UnitedHealth Group $UNH Price Target Raised to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927482</th>\n",
       "      <td>2020-07-16 18:49:34+00:00</td>\n",
       "      <td>Goldman Sachs Group $GS Price Target Raised to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926174</th>\n",
       "      <td>2020-07-16 20:19:16+00:00</td>\n",
       "      <td>RT @SharpStreetCap: And just like most of the ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at  \\\n",
       "14135  2020-04-09 00:00:03+00:00   \n",
       "13047  2020-04-09 02:23:18+00:00   \n",
       "12476  2020-04-09 03:59:33+00:00   \n",
       "11955  2020-04-09 05:58:02+00:00   \n",
       "6998   2020-04-09 14:42:56+00:00   \n",
       "...                          ...   \n",
       "929773 2020-07-16 16:11:19+00:00   \n",
       "929272 2020-07-16 16:44:54+00:00   \n",
       "928299 2020-07-16 17:50:52+00:00   \n",
       "927482 2020-07-16 18:49:34+00:00   \n",
       "926174 2020-07-16 20:19:16+00:00   \n",
       "\n",
       "                                                     text sentiment  \n",
       "14135   $HEXO target price is $2.21, HEXO has a upside...  positive  \n",
       "13047   #germany issuing €130.5b in 7 &amp; 15-yr #bon...  positive  \n",
       "12476   Wells Fargo &amp; Co Reiterates “Buy” Rating f...  positive  \n",
       "11955   This is not a favorable time to trade big. Why...  negative  \n",
       "6998    RT @amir: New: Microsoft’s rival to AWS, calle...  positive  \n",
       "...                                                   ...       ...  \n",
       "929773  Picked $amzn 3300 for earnings around 22. Shou...  positive  \n",
       "929272                         $AMZN $2992 you’re welcome  positive  \n",
       "928299  UnitedHealth Group $UNH Price Target Raised to...  positive  \n",
       "927482  Goldman Sachs Group $GS Price Target Raised to...  positive  \n",
       "926174  RT @SharpStreetCap: And just like most of the ...  negative  \n",
       "\n",
       "[876 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter out all unlabelled sentiment\n",
    "p_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/tweets_labelled.csv', sep=';',names=['created_at','text','sentiment']).query('sentiment == \"positive\"')\n",
    "n_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/tweets_labelled.csv', sep=';',names=['created_at','text','sentiment']).query('sentiment == \"negative\"')\n",
    "\n",
    "# Debug Print\n",
    "# display(p_df)\n",
    "# display(n_df)\n",
    "\n",
    "# Combine dataframes\n",
    "frames = [p_df, n_df]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# Sort by date\n",
    "# https://www.geeksforgeeks.org/how-to-sort-a-pandas-dataframe-by-date/\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df = df.sort_values(by=\"created_at\",ascending=True)\n",
    "# Debug Print\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$SPX</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$AMZN</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$AAPL</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$SPY</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$FB</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$TSLA</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$MSFT</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$QQQ</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$NFLX</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$JPM</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$DIS</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$ES_F</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$NVDA</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$BA</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$GOOGL</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$BTC</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$ZM</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$T</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$NDX</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$IWM</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$GOOG</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$BAC</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$BYND</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$INTC</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$JNJ</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        freq\n",
       "$SPX     132\n",
       "$AMZN     80\n",
       "$AAPL     79\n",
       "$SPY      69\n",
       "$FB       59\n",
       "$TSLA     40\n",
       "$MSFT     32\n",
       "$QQQ      29\n",
       "$NFLX     27\n",
       "$JPM      22\n",
       "$DIS      22\n",
       "$ES_F     20\n",
       "$NVDA     19\n",
       "$BA       17\n",
       "$GOOGL    16\n",
       "$BTC      16\n",
       "$ZM       15\n",
       "$T        15\n",
       "$NDX      15\n",
       "$IWM      15\n",
       "$GOOG     15\n",
       "$BAC      13\n",
       "$BYND     11\n",
       "$INTC     11\n",
       "$JNJ      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab the top 25 stocks\n",
    "ticker_pattern = re.compile(r'(^\\$[A-Z]+|^\\$ES_F)')\n",
    "\n",
    "# Break the string into a dictionary\n",
    "ticker_freq_dict = collections.defaultdict(int)\n",
    "# ticker_dict = collections.defaultdict(str)\n",
    "\n",
    "ticker = \"\"\n",
    "entry = \"\"\n",
    "for text in df['text']:\n",
    "    for word in text.split():\n",
    "        if ticker_pattern.fullmatch(word) is not None:\n",
    "            ticker_freq_dict[\"$\" + word[1:]] += 1\n",
    "    #         ticker = \"$\"+ word[1:]\n",
    "    #         if ticker not in ticker_dict:\n",
    "    #             ticker_dict[ticker] = []\n",
    "    #         entry = entry + word\n",
    "    # ticker_dict[ticker].append(entry)  \n",
    "    \n",
    "# ticker_freq_df = pd.DataFrame.from_dict(\n",
    "#     ticker_freq_dict, orient='index', columns=['freq'])\\\n",
    "#     .sort_values('freq', ascending=False).head(25)\n",
    "\n",
    "# Only store the top 25\n",
    "ticker_freq_df = pd.DataFrame.from_dict(\n",
    "    ticker_freq_dict, orient='index', columns=['freq'])\\\n",
    "    .nlargest(25, 'freq')\n",
    "display(ticker_freq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: $SPX expected: 132, Actual: 119\n",
      "ERROR: $AMZN expected: 80, Actual: 77\n",
      "ERROR: $AAPL expected: 79, Actual: 77\n",
      "ERROR: $SPY expected: 69, Actual: 66\n",
      "ERROR: $FB expected: 59, Actual: 62\n",
      "ERROR: $TSLA expected: 40, Actual: 41\n",
      "ERROR: $MSFT expected: 32, Actual: 33\n",
      "ERROR: $QQQ expected: 29, Actual: 31\n",
      "ERROR: $NFLX expected: 27, Actual: 28\n",
      "ERROR: $JPM expected: 22, Actual: 20\n",
      "ERROR: $ES_F expected: 20, Actual: 17\n",
      "ERROR: $NVDA expected: 19, Actual: 18\n",
      "ERROR: $BA expected: 17, Actual: 30\n",
      "ERROR: $GOOGL expected: 16, Actual: 17\n",
      "ERROR: $BTC expected: 16, Actual: 13\n",
      "ERROR: $ZM expected: 15, Actual: 11\n",
      "ERROR: $T expected: 15, Actual: 77\n",
      "ERROR: $IWM expected: 15, Actual: 17\n",
      "ERROR: $GOOG expected: 15, Actual: 31\n",
      "ERROR: $BAC expected: 13, Actual: 12\n",
      "ERROR: $BYND expected: 11, Actual: 9\n",
      "ERROR: $INTC expected: 11, Actual: 10\n",
      "ERROR: $JNJ expected: 10, Actual: 11\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of strings to save each stock within the dictionary\n",
    "ticker_dict = collections.defaultdict(str)\n",
    "\n",
    "# Iterate over the string\n",
    "for text in df['text']:\n",
    "    for ticker in ticker_freq_df.index:\n",
    "        if text.find(ticker) > 0:\n",
    "            if ticker not in ticker_dict:\n",
    "                ticker_dict[ticker] = [text]\n",
    "                continue\n",
    "            else:\n",
    "                ticker_dict[ticker].append(text)\n",
    "                continue\n",
    "\n",
    "# Print out the dictionary to json file for debugging purposes\n",
    "import json\n",
    "\n",
    "with open('ticker_dict.json','w') as fout:\n",
    "    json.dump(ticker_dict, fout, indent=4)\n",
    "\n",
    "# Confirm the correct amount of tweets have been written to the file\n",
    "for ticker in ticker_freq_df.index:\n",
    "    if len(ticker_dict[ticker]) != ticker_freq_dict[ticker]:\n",
    "        print(\"ERROR: \" + ticker + \" expected: \" + str(ticker_freq_dict[ticker]) + \", Actual: \" + str(len(ticker_dict[ticker])))\n",
    "\n",
    "with open('entry.json', 'w') as fout:\n",
    "    json.dump(ticker_dict['$JNJ'], fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a weight from 0-1 based on the percentage of positive tweets\n",
    "# ticker_dict = {\n",
    "#     \"$SPX\": [\n",
    "#         (timestamp, \"positive\"),\n",
    "#         (timestamp, \"negative\"),\n",
    "#         ...\n",
    "#     ],\n",
    "\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

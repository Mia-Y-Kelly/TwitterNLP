{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import re                                           # regular expressions\n",
    "import nltk\n",
    "import nltk.corpus as corpus                        # nltk package for reading files\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as stopwords      # words such as 'the','be','an', that don't significantly impact the sentiment\n",
    "from nltk.stem import WordNetLemmatizer             # Groups words\n",
    "from nltk.tokenize import word_tokenize             # Splits text into tokens\n",
    "import collections\n",
    "\n",
    "# Will be used later on\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# import sklearn\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out all unlabelled sentiment\n",
    "p_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/tweets_labelled.csv', sep=';',names=['created_at','text','sentiment']).query('sentiment == \"positive\"')\n",
    "n_df = pd.read_csv('/home/mia/Documents/College/CS4811/TwitterNLP/tweets_labelled.csv', sep=';',names=['created_at','text','sentiment']).query('sentiment == \"negative\"')\n",
    "\n",
    "# Debug Print\n",
    "# display(p_df)\n",
    "# display(n_df)\n",
    "\n",
    "# Combine dataframes\n",
    "frames = [p_df, n_df]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# Sort by date\n",
    "# https://www.geeksforgeeks.org/how-to-sort-a-pandas-dataframe-by-date/\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df = df.sort_values(by=\"created_at\",ascending=True)\n",
    "# Debug Print\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the top 25 stocks\n",
    "ticker_pattern = re.compile(r'(^\\$[A-Z]+|^\\$ES_F)')\n",
    "\n",
    "# Break the string into a dictionary\n",
    "ticker_freq_dict = collections.defaultdict(int)\n",
    "# ticker_dict = collections.defaultdict(str)\n",
    "\n",
    "# Count the frequencies of the mentions of each stock\n",
    "for text in df['text']:\n",
    "    for word in text.split():\n",
    "        if ticker_pattern.fullmatch(word) is not None:\n",
    "            if \"$\" + word not in ticker_freq_dict:\n",
    "                ticker_freq_dict[\"$\" + word[1:]] += 1\n",
    "    \n",
    "\n",
    "\n",
    "# Only store the top 25 mentioned stocks\n",
    "ticker_freq_df = pd.DataFrame.from_dict(ticker_freq_dict, orient='index', columns=['freq']).nlargest(25, 'freq')\n",
    "display(ticker_freq_df.sort_values('freq', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`ticker_dict`** intended structure\n",
    "There will be a key for each of the 25 most frequently mentioned stocks. Each Stock will have a list of all the sentiments about tweets relating to the stock, and the associated timestamp the tweet was made.\n",
    "```\n",
    "ticker_dict = {\n",
    "    \"$SPX\": [\n",
    "        [\n",
    "            \"Timestamp\",\n",
    "            \"Sentiment\" (positive or negative)\n",
    "        ]\n",
    "    ],\n",
    "    ,\n",
    "    \"$GOOGL\": [\n",
    "        [\n",
    "            \"Timestamp\",\n",
    "            \"Sentiment\" (positive or negative)\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary using the above structure\n",
    "ticker_dict = collections.defaultdict(str)\n",
    "\n",
    "# Iterate over all the tweets\n",
    "for text in df['text']:\n",
    "    # Determine which stocks the tweet is associated with, and store with appropriate stock\n",
    "    for ticker in ticker_freq_df.index:\n",
    "        if text.find(ticker) > 0:\n",
    "            # Put the store the sentiment and rating in a tuple to be stored in a list\n",
    "            row_df = df.query('text == @text')\n",
    "            timestamp = str(row_df.iat[0,0])\n",
    "            sentiment = row_df.iat[0,2]\n",
    "            entry = [timestamp, sentiment]\n",
    "            # print(entry)\n",
    "\n",
    "            if ticker not in ticker_dict:\n",
    "                ticker_dict[ticker] = [entry]\n",
    "                continue\n",
    "            else:\n",
    "                ticker_dict[ticker].append(entry)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the dictionary to json file for debugging purposes\n",
    "import json\n",
    "\n",
    "with open('/home/mia/Documents/College/CS4811/TwitterNLP/reference/ticker_dict.json','w') as fout:\n",
    "    json.dump(ticker_dict, fout, indent=4)\n",
    "\n",
    "# # Confirm the correct amount of tweets have been written to the file\n",
    "# for ticker in ticker_freq_df.index:\n",
    "#     if len(ticker_dict[ticker]) != ticker_freq_dict[ticker]:\n",
    "#         print(\"ERROR: \" + ticker + \" expected: \" + str(ticker_freq_dict[ticker]) + \", Actual: \" + str(len(ticker_dict[ticker])))\n",
    "\n",
    "# with open('entry.json', 'w') as fout:\n",
    "#     json.dump(ticker_dict['$JNJ'], fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a ticker_dict toDataframe\n",
    "sentiment_df = pd.DataFrame.from_dict(ticker_dict, orient='index')\n",
    "display(sentiment_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`sentiment_dict`** intended structure\n",
    "There will be a key for each of the 25 most frequently mentioned stocks. Each Stock have a list of days an the associated percentage of positive tweets.\n",
    "```\n",
    "ticker_dict = {\n",
    "    \"$SPX\": [\n",
    "        \"Day\": weight,\n",
    "        \"Day\": weight,\n",
    "        ...\n",
    "    ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a weight from 0-1 based on the percentage of positive tweets\n",
    "stock_weight_dict = dict()\n",
    "round_time_pattern = \" \" + \".*\"\n",
    "current_time = \"\"\n",
    "total = 0\n",
    "total_positive = 0\n",
    "\n",
    "created = []\n",
    "\n",
    "for stock in sentiment_df.index:\n",
    "    tweets = sentiment_df.loc[stock]\n",
    "       \n",
    "    for tweet in tweets:\n",
    "        if tweet is not None:\n",
    "            # print(tweet)\n",
    "            # round tweet to the day\n",
    "            # print(re.sub(round_time_pattern,'', tweet[0]))\n",
    "                        \n",
    "            current_time = re.sub(round_time_pattern, '', tweet[0])\n",
    "            current_time = re.sub(r'-','/', current_time)\n",
    "            \n",
    "            if current_time not in stock_weight_dict:\n",
    "                stock_weight_dict[current_time] = []\n",
    "            \n",
    "            # If it is a new date, reset the counter and calculate the percentage\n",
    "            if current_time not in created:\n",
    "                # If the total is 0, it is the first round\n",
    "                if total != 0:\n",
    "                    # print(current_time)\n",
    "                    # print(total)\n",
    "                    # print(total_positive)\n",
    "                    weight = round(total_positive/total, 2)\n",
    "                    if weight == .5:\n",
    "                        weight = 0\n",
    "                    elif weight < .5:\n",
    "                        weight = -1\n",
    "                    elif weight > .5:\n",
    "                        weight = 1\n",
    "                    stock_weight_dict[current_time].append({stock: weight})\n",
    "                    total = 0\n",
    "                    total_positive = 0\n",
    "                else:\n",
    "                    total += 1\n",
    "                    if tweet[1] == \"positive\":\n",
    "                        total_positive += 1\n",
    "                created.append(current_time)\n",
    "            else:\n",
    "                total += 1\n",
    "                if tweet[1] == \"positive\":\n",
    "                    total_positive += 1\n",
    "                \n",
    "            # print(created)\n",
    "    # break\n",
    "    created.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)           \n",
    "pp.pprint(stock_weight_dict)\n",
    "\n",
    "with open('/home/mia/Documents/College/CS4811/TwitterNLP/reference/sentiment.json', 'w') as fout:\n",
    "    json.dump(stock_weight_dict, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_to_csv(stock):\n",
    "    # create a dataframe of just the stock and its date\n",
    "    counter = 0\n",
    "    single_stock_df = pd.DataFrame(columns=['Date', stock])\n",
    "    for date in stock_weight_dict:\n",
    "        for entries in stock_weight_dict[date]:\n",
    "            if stock in entries:\n",
    "                single_stock_df.loc[counter] = [date, entries[stock]]\n",
    "                counter = counter + 1\n",
    "                break\n",
    "    stock = re.sub(r'\\$','',stock)\n",
    "    # print(stock)\n",
    "    single_stock_df.to_csv(\"/home/mia/Documents/College/CS4811/TwitterNLP/twt_data/\"+stock+\".csv\",index=False)\n",
    "    return\n",
    "    \n",
    "for stock in ticker_freq_df.index:\n",
    "    stock_to_csv(stock)\n",
    "\n",
    "for ticker in ticker_freq_df.index:\n",
    "    ticker_freq_df.rename(index={ticker: re.sub(r\"\\$\",\"\",ticker)}, inplace=True)\n",
    "ticker_freq_df.to_csv(\"/home/mia/Documents/College/CS4811/TwitterNLP/twt_data/stocks_list.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
